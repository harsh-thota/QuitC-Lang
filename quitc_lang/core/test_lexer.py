# from lexer import Token
# from env import Environment
# from parser import Parser
# from interpreter import Interpreter

# source_code = """
# /*int x = 5 ğŸ¤¡*/ // declare x
# /*print(x) ğŸ˜‚ // show x

# function int double(n) {
#   return n * 2 ğŸ¤¡ // double it
# }

# int result = double(4) ğŸ¤¡ // should be 8
# print(result) ğŸ˜‚ // print 8*/

# int z = 5 ğŸ¤¡ // test value
# if (z > 3) {
#   print("yes") ğŸ˜‚ //yep, it's true
# } else {
#   print("no") ğŸ˜­ //no, its not!
# }

# int i = 0 ğŸ¤¡ // initialize

# while (i < 3) {
#   print(i) ğŸ˜‚ // print i
#   i = i + 1 ğŸ¤¡ // increment
# }

# try {
#   print("trying...") ğŸ˜‚ //tryingggg
#   int oops = 5 / 0 ğŸ¤¡ // will crash
#   print("you won't see this") ğŸ˜ˆ //will i see this?
# } catch {
#   print("nice try") ğŸ’€ //nice try
# }

# int o = -5 ğŸ¤¡ // test negation
# print(o) ğŸ˜‚ //forget comment

# int p = 0 ğŸ¤¡//
# if (!p) {
#     print("zero is falsy") ğŸ˜‚//forget comment?
# }

# """

# print("=== TOKENIZING ===")
# tokens = []
# try:
#     tokens = Token.tokenize(source_code)
#     print(f"Generated {len(tokens)} tokens:")
#     for token in tokens:
#         print(f"  {token}")
# except Exception as e:
#     print(f"Tokenizer error: {e}")

# print("\n=== PARSING ===")
# ast = None
# try:
#     parser = Parser(tokens)
#     ast = parser.parse()
#     print(f"AST: {ast}")
# except Exception as e:
#     print(f"Parser error: {e}")

# print("\n=== INTERPRETING ===")
# try:
#     if ast is not None:
#         env = Environment()
#         interpreter = Interpreter(env)
#         interpreter.execute(ast)
#     else:
#         print("Skipping interpretation - no valid AST")
# except Exception as e:
#     print(f"Interpreter error: {e}")

# print("\n=== DONE ===")